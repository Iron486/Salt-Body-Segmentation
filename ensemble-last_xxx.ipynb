{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <font color='Lime'>Import libraries</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "00833d394e3069216af171fd979c814e7e1e430d",
    "execution": {
     "iopub.execute_input": "2022-09-04T21:53:23.441233Z",
     "iopub.status.busy": "2022-09-04T21:53:23.440201Z",
     "iopub.status.idle": "2022-09-04T21:53:35.624571Z",
     "shell.execute_reply": "2022-09-04T21:53:35.623264Z",
     "shell.execute_reply.started": "2022-09-04T21:53:23.441146Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "!pip install segmentation-models\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "0e26e21ff39e8b2afc0003fec4e4f5269f61aa4c",
    "execution": {
     "iopub.execute_input": "2022-09-04T21:53:37.083073Z",
     "iopub.status.busy": "2022-09-04T21:53:37.082388Z",
     "iopub.status.idle": "2022-09-04T21:53:37.088050Z",
     "shell.execute_reply": "2022-09-04T21:53:37.087038Z",
     "shell.execute_reply.started": "2022-09-04T21:53:37.083031Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "im_width = 128\n",
    "im_height = 128\n",
    "im_chan = 1\n",
    "#path_train = r'C:\\\\Users\\diego\\OneDrive\\Desktop\\DS\\seismic_segmentation\\train'\n",
    "#path_test = r'C:\\\\Users\\diego\\OneDrive\\Desktop\\DS\\seismic_segmentation\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T21:53:38.463063Z",
     "iopub.status.busy": "2022-09-04T21:53:38.462391Z",
     "iopub.status.idle": "2022-09-04T21:53:38.470992Z",
     "shell.execute_reply": "2022-09-04T21:53:38.469869Z",
     "shell.execute_reply.started": "2022-09-04T21:53:38.463027Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "89455be399a79910334eb76beafc40bcdab08f83"
   },
   "source": [
    "##   <font color='Lime'>Data Analysis</font> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "97114b7b4f28347130dc3e44af5469d6efdf7ab1",
    "execution": {
     "iopub.execute_input": "2022-09-04T21:53:42.284232Z",
     "iopub.status.busy": "2022-09-04T21:53:42.283561Z",
     "iopub.status.idle": "2022-09-04T21:53:48.917625Z",
     "shell.execute_reply": "2022-09-04T21:53:48.916592Z",
     "shell.execute_reply.started": "2022-09-04T21:53:42.284197Z"
    }
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "path_train = r'../input/tgs-salt-identification-challenge/train.zip'\n",
    "path_test = r'../input/tgs-salt-identification-challenge/test.zip'\n",
    "\n",
    "unziped_train= '/kaggle/working/unziped_train'\n",
    "unziped_test= '/kaggle/working/unziped_test'\n",
    "with zipfile.ZipFile(\"../input/tgs-salt-identification-challenge/train\"+\".zip\",\"r\") as z:\n",
    "    z.extractall(unziped_train)\n",
    "with zipfile.ZipFile(\"../input/tgs-salt-identification-challenge/test\"+\".zip\",\"r\") as z:\n",
    "    z.extractall(unziped_test)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ids= ['1f1cc6b3a4','5b7c160d0d','6c40978ddf','7dfdf6eeb8','7e5a6e5013']\n",
    "plt.figure(figsize=(20,10))\n",
    "for j, img_name in enumerate(ids):\n",
    "    q = j+1\n",
    "    img = load_img('./masks' + img_name + '.png')\n",
    "    img_mask = load_img('./images' + img_name + '.png')\n",
    "    \n",
    "    plt.subplot(1,2*(1+len(ids)),q*2-1)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1,2*(1+len(ids)),q*2)\n",
    "    plt.imshow(img_mask)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T21:53:48.920427Z",
     "iopub.status.busy": "2022-09-04T21:53:48.919472Z",
     "iopub.status.idle": "2022-09-04T21:53:48.940294Z",
     "shell.execute_reply": "2022-09-04T21:53:48.939221Z",
     "shell.execute_reply.started": "2022-09-04T21:53:48.920389Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "train_ids=[]\n",
    "test_ids=[]\n",
    "for i in os.listdir(os.path.join(unziped_train,\"images\")):\n",
    "    train_ids.append(i)\n",
    "for i in os.listdir(os.path.join(unziped_test,\"images\")):\n",
    "    test_ids.append(i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a8f02165966489c8a21bb7127bb88e7cf607599d",
    "execution": {
     "iopub.execute_input": "2022-09-04T21:53:48.942203Z",
     "iopub.status.busy": "2022-09-04T21:53:48.941812Z",
     "iopub.status.idle": "2022-09-04T21:54:06.408813Z",
     "shell.execute_reply": "2022-09-04T21:54:06.407736Z",
     "shell.execute_reply.started": "2022-09-04T21:53:48.942168Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get and resize train images and masks\n",
    "import numpy as np\n",
    "X_train1 = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
    "Y_train1 = np.zeros((len(train_ids), im_height, im_width, 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = unziped_train\n",
    "    img = load_img(path + '/images/' + id_)\n",
    "    x = img_to_array(img)[:,:,1]\n",
    "    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "    X_train1[n] = x\n",
    "    mask = img_to_array(load_img(path + '/masks/' + id_))[:,:,1]\n",
    "    Y_train1[n] = resize(mask, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "faf6ea42655fb0f5ee8994a65a7c3bef888ef1ae",
    "execution": {
     "iopub.execute_input": "2022-09-04T21:54:06.411556Z",
     "iopub.status.busy": "2022-09-04T21:54:06.411093Z",
     "iopub.status.idle": "2022-09-04T21:54:06.804455Z",
     "shell.execute_reply": "2022-09-04T21:54:06.803493Z",
     "shell.execute_reply.started": "2022-09-04T21:54:06.411500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if training data looks all right\n",
    "ix = random.randint(0, len(train_ids))\n",
    "plt.imshow(np.dstack((X_train1[ix],X_train1[ix],X_train1[ix])))\n",
    "plt.show()\n",
    "tmp = np.squeeze(Y_train1[ix]).astype(np.float32)\n",
    "plt.imshow(np.dstack((tmp,tmp,tmp)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T21:54:06.806413Z",
     "iopub.status.busy": "2022-09-04T21:54:06.806054Z",
     "iopub.status.idle": "2022-09-04T21:54:06.815276Z",
     "shell.execute_reply": "2022-09-04T21:54:06.814201Z",
     "shell.execute_reply.started": "2022-09-04T21:54:06.806377Z"
    }
   },
   "outputs": [],
   "source": [
    "def Intersection_over_Union(y_true, y_pred, threshold=0.5):\n",
    "    y_pred = K.squeeze(tf.cast(y_pred > threshold,tf.int32), -1)\n",
    "    y_true = K.cast(y_true[..., 0], K.floatx())\n",
    "    y_pred = K.cast(y_pred, K.floatx())\n",
    "    truth_areas = K.sum(y_true, axis=[1, 2])\n",
    "    pred_areas = K.sum(y_pred, axis=[1, 2])\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = K.clip(truth_areas + pred_areas - intersection, 1e-9, 128 * 128)\n",
    "    check = K.map_fn(lambda x: K.equal(x, 0), truth_areas + pred_areas, dtype=tf.bool) #images with no predicted and true salt bodies\n",
    "    p = intersection / union #ratio for each image\n",
    "    iou = K.switch(check, p + 1., p) # put 1 for images where no salt bodies were found \n",
    "\n",
    "    prec = K.map_fn(lambda x: K.mean(K.greater(x, np.arange(0.5, 1.0, 0.05))), iou, dtype=tf.float32) \n",
    "    #does each image have a iou greater than threshold? if so, the image iou is used to calculate the mean\n",
    "    prec_iou = K.mean(prec)\n",
    "    return prec_iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color='Lime'>Data Augmentation</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c6d376a5ed9fa0ff708299f55a0a8ed8b8471137",
    "execution": {
     "iopub.execute_input": "2022-09-04T21:54:06.817335Z",
     "iopub.status.busy": "2022-09-04T21:54:06.816694Z",
     "iopub.status.idle": "2022-09-04T21:54:47.551769Z",
     "shell.execute_reply": "2022-09-04T21:54:47.550750Z",
     "shell.execute_reply.started": "2022-09-04T21:54:06.817299Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm_notebook(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = unziped_test\n",
    "    img = load_img(path + '/images/' + id_)\n",
    "    x = img_to_array(img)[:,:,1]\n",
    "    sizes_test.append([x.shape[0], x.shape[1]])\n",
    "    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "    X_test[n] = x\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T22:20:41.389517Z",
     "iopub.status.busy": "2022-09-04T22:20:41.389156Z",
     "iopub.status.idle": "2022-09-04T22:20:41.396422Z",
     "shell.execute_reply": "2022-09-04T22:20:41.395380Z",
     "shell.execute_reply.started": "2022-09-04T22:20:41.389486Z"
    }
   },
   "outputs": [],
   "source": [
    "#step=n*(#images/batch_size)\n",
    "#learning_rate = initial_learning_rate * decay_rate ^ (step / decay_steps)\n",
    "0.000018 * 0.9**(23*(3600/20) / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T22:29:17.225125Z",
     "iopub.status.busy": "2022-09-04T22:29:17.224760Z",
     "iopub.status.idle": "2022-09-04T23:59:48.439453Z",
     "shell.execute_reply": "2022-09-04T23:59:48.438455Z",
     "shell.execute_reply.started": "2022-09-04T22:29:17.225094Z"
    }
   },
   "outputs": [],
   "source": [
    "from albumentations import (HorizontalFlip, ShiftScaleRotate, RandomContrast, RandomBrightness, Compose,Rotate)\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#tf.random.set_seed(42)\n",
    "#\n",
    "#import keras\n",
    "#from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "import segmentation_models as sm\n",
    "sm.set_framework('tf.keras')\n",
    "\n",
    "\n",
    "checkpoint=r\"models/checkpoint\"\n",
    "if  os.path.exists(os.path.join(os.getcwd(),checkpoint))==False:\n",
    "    if  os.path.exists(os.path.join(os.getcwd(),'models'))==False:\n",
    "        os.mkdir('models/')\n",
    "    os.mkdir(checkpoint)\n",
    "\n",
    "from tensorflow.keras.optimizers import schedules\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.000029,\n",
    "    decay_steps=6000,\n",
    "    decay_rate=0.89\n",
    "    )\n",
    "\n",
    "\n",
    "opt = Adam(\n",
    "    learning_rate=lr_schedule, # add exponential decay\n",
    "    epsilon=1e-08)\n",
    "\n",
    "sm.framework()\n",
    "nets = 15\n",
    "model = [0] *nets\n",
    "N=1\n",
    "backbone='resnet34'\n",
    "best_models=[]\n",
    "for j in range(nets):\n",
    "    \n",
    "    base_model = sm.Unet(backbone, encoder_weights='imagenet')# classes=1, activation='sigmoid')\n",
    "    inp = Input(shape=(None, None, N))\n",
    "    s = Lambda(lambda x: x / 255)(inp)\n",
    "    l1 = tf.keras.layers.Conv2D(3, (1, 1))(s) # map N channels data to 3 channels\n",
    "    out = base_model(l1)\n",
    "\n",
    "    model[j] = Model(inp, out, name=base_model.name)\n",
    "    model[j].compile(optimizer=opt, loss='binary_crossentropy', metrics=[Intersection_over_Union])# metrics=[tf.keras.metrics.MeanIoU(num_classes=2)])\n",
    "\n",
    "    # summarize the model\n",
    "\n",
    "    model[j].summary()\n",
    "\n",
    "    #model_checkpoint = tf.keras.callbacks.ModelCheckpoint(os.path.join(os.getcwd(),checkpoint),\n",
    "       # save_weights_only=True,\n",
    "       # monitor='val_Intersection_over_Union',\n",
    "        #mode='max',\n",
    "       # save_best_only=True)\n",
    "\n",
    "earlystopper = EarlyStopping(patience=7,monitor='val_Intersection_over_Union', mode='max'\n",
    "                             , verbose=1,restore_best_weights=True)\n",
    "histories=[]\n",
    "\n",
    "#checkpointer = ModelCheckpoint('model-tgs-salt-1.h5', verbose=1, save_best_only=True)\n",
    "for j in range(nets):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train1, Y_train1, test_size = 0.1)\n",
    "    transform = A.Compose([\n",
    "        HorizontalFlip(p=0.5)])\n",
    "    transformed = transform(image=np.squeeze(X_train), mask=np.squeeze(y_train))\n",
    "    history = model[j].fit( np.expand_dims(transformed['image'],axis=3),np.expand_dims(transformed['mask'],axis=3),validation_data = (X_val,y_val)\n",
    "                              , batch_size=20, epochs=26, callbacks=[earlystopper])\n",
    "    histories.append(history)\n",
    "    print(os.getcwd())\n",
    "\n",
    "    #save the model\n",
    "    \n",
    "    name=str(j)+'CNN_Unet_onlyflip_exponentialdecay_cross_entropy_early_stop_IoU_ensemble'\n",
    "    \n",
    "    \n",
    "    #with open(\"y_train\", \"wb\") as f:\n",
    "       # pickle.dump(y_train, f)\n",
    "    \n",
    "    #os.mkdir('models/')\n",
    "    if  os.path.exists(os.path.join(os.getcwd(),'models/'))==False:\n",
    "        os.mkdir('models/')\n",
    "    #model[j].save('models/'+name+'.h5')\n",
    "    \n",
    "    #plt.gca().set_xlim(0,33)\n",
    "\n",
    "\n",
    "    if  os.path.exists(os.path.join(os.getcwd(),'plots/'))==False:\n",
    "        os.mkdir('plots/')\n",
    "\n",
    "    \n",
    "     \n",
    "    \n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "\n",
    "    plt.title('Model Loss and Accuracy',fontsize=14,y=1.03 )\n",
    "    plt.grid( True )    \n",
    "\n",
    "    plt.ylabel('Loss and Accuracy',labelpad=7,fontsize=10)    \n",
    "    plt.xlabel('Epochs',labelpad=7,fontsize=10)   \n",
    "    plt.gca().set_ylim(0,1)\n",
    "    plt.savefig(os.path.join('plots',name+'.png'), dpi=500, bbox_inches='tight',facecolor=(1, 1, 1) )\n",
    "\n",
    "    \n",
    "    #plot loss and accuracy\n",
    "    loss, accuracy = model[j].evaluate(X_val,y_val)\n",
    "    \n",
    "    \n",
    "    #plt.gca().set_ylim(0,1)\n",
    "    #plt.grid(True)\n",
    "    if  os.path.exists(os.path.join(os.getcwd(),'models/details'))==False:\n",
    "        os.mkdir('models/details')\n",
    "    with open(os.path.join('models/details',name+'.txt'), 'w+') as f:\n",
    "        f.write(f'{name} \\n  \\n ')\n",
    "        f.write(f'accuracy : {round(accuracy*100,4)} \\n loss : {round(loss,4)}  \\n ')\n",
    "        f.write(f' \\n optimizer: \\n {model[j].optimizer.get_config()}')\n",
    "    #evaluate loss and accuracy\n",
    "    threshold=0.65\n",
    "    if  os.path.exists(os.path.join(os.getcwd(),'models/accurate'))==False:\n",
    "        os.mkdir('models/accurate')\n",
    "    if accuracy >threshold:\n",
    "        model[j].save_weights('models/accurate'+name+'.h5')\n",
    "        with open(name, \"wb\") as f:\n",
    "            pickle.dump(model[j].predict(X_test), f)\n",
    "        best_models.append(j)\n",
    "    print('Accuracy: %f' % (accuracy*100),'Loss: %f' % (loss))    \n",
    "\n",
    "\n",
    "#print accuracy \n",
    "\n",
    "\n",
    "#X_train,X_val,y_train,y_val = train_test_split(X_train,Y_train, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = np.zeros( X )\n",
    "#for j in range(nets):\n",
    "    #results = results + model[j].predict(X_test)\n",
    "#results = np.argmax(results,axis = 1)\n",
    "#results = pd.Series(results,name=\"Label\")\n",
    "#results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T01:52:01.290318Z",
     "iopub.status.busy": "2022-09-05T01:52:01.289940Z",
     "iopub.status.idle": "2022-09-05T01:52:01.300037Z",
     "shell.execute_reply": "2022-09-05T01:52:01.298899Z",
     "shell.execute_reply.started": "2022-09-05T01:52:01.290288Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'/kaggle/working')\n",
    "from IPython.display import FileLink\n",
    "#FileLink('./models/accurate10CNN_Unet_onlyflip_exponentialdecay_cross_entropy_early_stop_IoU_ensemble.h5')\n",
    "FileLink('0CNN_Unet_onlyflip_exponentialdecay_cross_entropy_early_stop_IoU_ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NotebookApp.iopub_msg_rate_limit=8000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENSEMBLE PREDICTIONS AND SUBMIT\n",
    "results = []\n",
    "for j in range(nets):\n",
    "    results = results + model[j].predict(X_val)\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.Series(results,name=\"Label\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0d66a11a8d8d48e16640307185062f5494c1f5b6"
   },
   "source": [
    "##  <font color='Lime'>Train the model</font> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color='Lime'>Save the model and plot accuracy and loss</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.load_weights(os.path.join('models/',name+'_weights.h5'))\n",
    "model.evaluate(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color='Lime'>Accuracy and Loss</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'accuracy : {round(accuracy*100,3)} \\n loss : {round(loss,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize activation functions\n",
    "for i, layer in enumerate (model.layers):\n",
    "    print (i, layer)\n",
    "    try:\n",
    "        print (\"    \",layer.activation)\n",
    "    except AttributeError:\n",
    "        print('   no activation attribute')\n",
    "#specific info about each layer\n",
    "for i in range(len(model.layers)):\n",
    "    print(f'{i}   {model.layers[i]}: \\n{model.layers[i].get_config()} \\n')\n",
    "#info about optimizers\n",
    "model.optimizer.get_config()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color='Lime'>Load the model</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = saved_model.evaluate(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here I plotted the images based on columns and z_max (defined by the user, but it should be a multiple of the # of columns)\n",
    "#columns = 20\n",
    "n_images=100\n",
    "columns=10\n",
    "\n",
    "\n",
    "images=X_val[:n_images]\n",
    "\n",
    "\n",
    "#int(len(images)/columns)\n",
    "\n",
    "fig,axes=plt.subplots(int(len(images)/columns),columns,figsize=(40,20))\n",
    "fig.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.463, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for i,ind in enumerate(images):\n",
    "    #print(images_class)\n",
    "    fig.suptitle(f'First {n_images} sections in the dataset',fontsize=26, x=0.2812,y=0.946)\n",
    "    #print(j,image)\n",
    "    axes[int(i/columns), i % columns].imshow(ind)\n",
    "    #axes[int((i)*(len(ind)/columns)+(int(j/columns))),j % columns] #.set_title(f'{classes[i]}',pad=10)\n",
    "#image_plotting(X_test[:1])\n",
    "plt.savefig(os.path.join('plots/','100_images_in_the_dataset_white.png'), dpi=300,facecolor='w',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5ab8516fb8ab135872dd4f4b895b5d76206df1fa"
   },
   "source": [
    "##  <font color='Lime'>Test Data</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2316034edcb7227673fd9b69264ca9c0d0e87f14"
   },
   "outputs": [],
   "source": [
    "for j in range(nets):\n",
    "    pred=model[j].predict(X_test)\n",
    "    np.save(os.path.join('models',str(j)),pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink  \n",
    "os.chdir(r'/kaggle/working')\n",
    "#FileLink(r'models/'+str(0)+'.npy')\n",
    "#FileLink(r'models/'+str(1)+'.npy')\n",
    "#FileLink(r'models/'+str(2)+'.npy')\n",
    "#FileLink(r'models/'+str(3)+'.npy')\n",
    "#FileLink(r'models/'+str(4)+'.npy')\n",
    "#FileLink(r'models/'+str(5)+'.npy')\n",
    "#FileLink(r'models/'+str(6)+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for j in range(nets):\n",
    "    pred=np.load(os.path.join('models',str(j)+'.npy'))\n",
    "    results.append(pred)\n",
    "#results = np.argmax(results,axis = 1)\n",
    "#results = pd.Series(results,name=\"Label\")\n",
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af64790cdb7e5beb05fc34635cdf092124d7dc20"
   },
   "outputs": [],
   "source": [
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in tnrange(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7da5a47444df98205dd7039223868b5d67f15400"
   },
   "outputs": [],
   "source": [
    "preds_test_upsampled[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "844cded40edc71652bc5b26852245e37f46f6448"
   },
   "source": [
    "##  <font color='Lime'>Submission</font> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "73336f76166028ba39c8164083c9564a0d5afe40"
   },
   "outputs": [],
   "source": [
    "def RLenc(img, order='F', format=True):\n",
    "    \"\"\"\n",
    "    img is binary mask image, shape (r,c)\n",
    "    order is down-then-right, i.e. Fortran\n",
    "    format determines if the order needs to be preformatted (according to submission rules) or not\n",
    "\n",
    "    returns run length as an array or string (if format is True)\n",
    "    \"\"\"\n",
    "    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n",
    "    runs = []  ## list of run lengths\n",
    "    r = 0  ## the current run length\n",
    "    pos = 1  ## count starts from 1 per WK\n",
    "    for c in bytes:\n",
    "        if (c == 0):\n",
    "            if r != 0:\n",
    "                runs.append((pos, r))\n",
    "                pos += r\n",
    "                r = 0\n",
    "            pos += 1\n",
    "        else:\n",
    "            r += 1\n",
    "\n",
    "    # if last run is unsaved (i.e. data ends with 1)\n",
    "    if r != 0:\n",
    "        runs.append((pos, r))\n",
    "        pos += r\n",
    "        r = 0\n",
    "\n",
    "    if format:\n",
    "        z = ''\n",
    "\n",
    "        for rr in runs:\n",
    "            z += '{} {} '.format(rr[0], rr[1])\n",
    "        return z[:-1]\n",
    "    else:\n",
    "        return runs\n",
    "\n",
    "pred_dict = {fn[:-4]:RLenc(np.round(preds_test_upsampled[i])) for i,fn in tqdm_notebook(enumerate(test_ids))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6eaf7acaf4a0678638c5e40732c6533816777637"
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv('submission_unet_cross_entropy_lovasz.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
